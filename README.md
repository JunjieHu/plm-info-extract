# Pre-train LM for Information Extraction

## Meeting Note:
- 06/13/2022


## Related Papers
- Mintz et al. ACL'09. [Distant supervision for relation extraction without labeled data](https://aclanthology.org/P09-1113.pdf)
- Thillaisundaram et al. BioNLP'19. [Biomedical relation extraction with pre-trained language representations
and minimal task-specific architecture](https://aclanthology.org/D19-5713.pdf)
- Alt et al. ACL'19. [Fine-tuning Pre-Trained Transformer Language Models to Distantly
Supervised Relation Extraction](https://aclanthology.org/P19-1134.pdf)
- Wang et al. ACL'22. [OIE@OIA: an Adaptable and Efficient Open Information Extraction
Framework](https://aclanthology.org/2022.acl-long.430.pdf)
